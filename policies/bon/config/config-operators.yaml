---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-snrc
spec:
  evaluationInterval:
    compliant: 1m
    noncompliant: 1m
  object-templates-raw: |
    {{- if not (hasKey (lookup "operators.coreos.com/v1alpha1" "Subscription" "openshift-workload-availability" "self-node-remediation").metadata.labels "policies.ignore") }}
    {{- if ne "HighlyAvailable" (fromClusterClaim "controlplanetopology.openshift.io") }}
    - complianceType: mustnothave
      objectDefinition:
        apiVersion: self-node-remediation.medik8s.io/v1alpha1
        kind: SelfNodeRemediationConfig
        metadata:
          name: self-node-remediation-config
          namespace: openshift-workload-availability
    {{- else }}
    - complianceType: musthave
      objectDefinition:
        apiVersion: self-node-remediation.medik8s.io/v1alpha1
        kind: SelfNodeRemediationConfig
        metadata:
          name: self-node-remediation-config
          namespace: openshift-workload-availability
        spec:
          peerUpdateInterval: 1m
          customDsTolerations:
          - effect: NoSchedule
            operator: Exists
            key: node-role.kubernetes.io/infra
    {{- end }}
    {{- end }}
  remediationAction: enforce
  severity: low
---
apiVersion: operators.coreos.com/v1
kind: OLMConfig
metadata:
  name: cluster
spec:
  features:
    disableCopiedCSVs: true
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-master
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/master
      operator: Exists
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-worker
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/worker
      operator: Exists
    - key: node-role.kubernetes.io/master
      operator: DoesNotExist
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-infra
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/infra
      operator: Exists
    - key: node-role.kubernetes.io/worker
      operator: DoesNotExist
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-acm
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/acm
      operator: Exists
    - key: node-role.kubernetes.io/worker
      operator: DoesNotExist
    - key: node-role.kubernetes.io/infra
      operator: DoesNotExist
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
kind: Namespace
apiVersion: v1
metadata:
  name: ocp-logging
  annotations:
    openshift.io/node-selector: node-role.kubernetes.io/infra=
    scheduler.alpha.kubernetes.io/defaultTolerations: '[{"operator":"Exists","effect":"NoSchedule","key":"node-role.kubernetes.io/infra"}]'
  labels:
    openshift.io/cluster-monitoring: "true"
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: eventrouter
  namespace: ocp-logging
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: event-reader
rules:
- apiGroups: [""]
  resources: ["events"]
  verbs: ["get", "watch", "list"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: event-reader-binding
subjects:
- kind: ServiceAccount
  name: eventrouter
  namespace: ocp-logging
roleRef:
  kind: ClusterRole
  name: event-reader
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: eventrouter
  namespace: ocp-logging
data:
  config.json: |-
    {
      "sink": "stdout"
    }
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: eventrouter
  namespace: ocp-logging
  labels:
    component: "eventrouter"
    logging-infra: "eventrouter"
    provider: "openshift"
spec:
  selector:
    matchLabels:
      component: "eventrouter"
      logging-infra: "eventrouter"
      provider: "openshift"
  replicas: 1
  template:
    metadata:
      labels:
        component: "eventrouter"
        logging-infra: "eventrouter"
        provider: "openshift"
      name: eventrouter
    spec:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      serviceAccount: eventrouter
      containers:
      - name: kube-eventrouter
        image: registry.redhat.io/openshift-logging/eventrouter-rhel9:v0.4
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - name: config-volume
          mountPath: /etc/eventrouter
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
          readOnlyRootFilesystem: true
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      volumes:
      - name: config-volume
        configMap:
          name: eventrouter
      tolerations:
      - effect: NoExecute
        key: node.kubernetes.io/not-ready
        operator: Exists
        tolerationSeconds: 30
      - effect: NoExecute
        key: node.kubernetes.io/unreachable
        operator: Exists
        tolerationSeconds: 30
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: log-collector
  namespace: openshift-logging
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: collect-application-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: collect-application-logs
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: collect-audit-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: collect-audit-logs
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: collect-infrastructure-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: collect-infrastructure-logs
---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-logforwarder
spec:
  evaluationInterval:
    compliant: 1m
    noncompliant: 1m
  remediationAction: enforce
  severity: high
  object-templates-raw: |
    {{- if not (hasKey (lookup "operators.coreos.com/v1alpha1" "Subscription" "openshift-logging" "cluster-logging").metadata.labels "policies.ignore") }}
    {{hub- $kg := index .ManagedClusterLabels "policies.kafka-group" hub}}
    {{hub- $eb := (cat $kg "eventBrokers" | replace " " "") hub}}
    {{hub- $ib := (cat $kg "infraBrokers" | replace " " "") hub}}
    {{hub- if and (hasKey (lookup "v1" "ConfigMap" "policies" "config-operators").data $eb) (hasKey (lookup "v1" "ConfigMap" "policies" "config-operators").data $ib) hub}}
    {{hub- $su := index .ManagedClusterLabels "policies.syslog-url" hub}}
    {{hub- $et := index .ManagedClusterLabels "policies.event-topic" hub}}
    {{hub- $it := index .ManagedClusterLabels "policies.infra-topic" hub}}
    {{hub- if ne "" (cat $su $et $it | replace " " "") hub}}
    - complianceType: mustonlyhave
      objectDefinition:
        apiVersion: observability.openshift.io/v1
        kind: ClusterLogForwarder
        metadata:
          name: log-forwarder
          namespace: openshift-logging
        spec:
          collector:
            resources:
              limits:
                cpu: "1"
                memory: 2Gi
              requests:
                cpu: "1"
                memory: 2Gi
            tolerations:
            - effect: NoSchedule
              key: node-role.kubernetes.io/infra
              operator: Exists
          serviceAccount:
            name: log-collector
          inputs:
          - name: eventrouter
            application:
              includes:
              - namespace: ocp-logging
              selector:
                matchLabels:
                  component: eventrouter
            type: application
          - name: infra-log
            infrastructure:
              sources:
              - container
            type: infrastructure
          - name: journal-log
            infrastructure:
              sources:
              - node
            type: infrastructure
          - name: audit-log
            audit:
              sources:
              - kubeAPI
              - openshiftAPI
              - ovn
            type: audit
          outputs:
    {{hub- if ne "" $it hub}}
          - name: infra-receiver
            kafka:
              brokers: {{hub index (lookup "v1" "ConfigMap" "policies" "config-operators").data $ib hub}}
              topic: {{hub index .ManagedClusterLabels "policies.infra-topic" hub}}
              tuning:
                compression: none
                deliveryMode: AtLeastOnce
                maxWrite: 10M
            type: kafka
    {{hub- end hub}}
    {{hub- if ne "" $et hub}}
          - name: event-receiver
            kafka:
              brokers: {{hub index (lookup "v1" "ConfigMap" "policies" "config-operators").data $eb hub}}
              topic: {{hub index .ManagedClusterLabels "policies.event-topic" hub}}
              tuning:
                compression: none
                deliveryMode: AtLeastOnce
                maxWrite: 10M
            type: kafka
    {{hub- end hub}}
    {{hub- if ne "" $su hub}}
          - name: rsyslog
            syslog:
              facility: user
              rfc: RFC5424
              severity: debug
              url: tcp://{{hub (splitn ".." 2 $su)._0 hub}}:{{hub (splitn ".." 2 $su)._1 hub}}
            type: syslog
    {{hub- end hub}}
          pipelines:
    {{hub- if or (ne "" $it) (ne "" $su) hub}}
          - name: audit-log
            inputRefs:
            - audit-log
            outputRefs:
    {{hub- if ne "" $it hub}}
            - infra-receiver
    {{hub- end hub}}
    {{hub- if ne "" $su hub}}
            - rsyslog
    {{hub- end hub}}
            filterRefs:
            - add-cluster-name
            - audit-log-drop-verb
            - audit-log-drop-resource
            - audit-log-drop-username
    {{hub- end hub}}
    {{hub- if or (ne "" $et) (ne "" $su) hub}}
          - name: journal-log
            inputRefs:
            - journal-log
            outputRefs:
    {{hub- if ne "" $et hub}}
            - event-receiver
    {{hub- end hub}}
    {{hub- if ne "" $su hub}}
            - rsyslog
    {{hub- end hub}}
            filterRefs:
            - add-cluster-name
            - journal-filter
            - multiline
            - journal-prune
          - name: event-log
            inputRefs:
            - eventrouter
            outputRefs:
    {{hub- if ne "" $su hub}}
            - rsyslog
    {{hub- end hub}}
            filterRefs:
            - add-cluster-name
            - multiline
            - event-prune
    {{hub- end hub}}
    {{hub- if ne "" $it hub}}
          - name: infra-log
            inputRefs:
            - infra-log
            outputRefs:
            - infra-receiver
            filterRefs:
            - add-cluster-name
            - important
            - core-infra-log
    {{hub- end hub}}
    {{hub- if ne "" $et hub}}
          - name: event-kafka
            inputRefs:
            - eventrouter
            outputRefs:
            - event-receiver
            filterRefs:
            - add-cluster-name
            - multiline
            - event-kafka-prune
            - event-kafka-drop
    {{hub- end hub}}
          filters:
          - name: add-cluster-name
            type: openshiftLabels
            openshiftLabels:
              cluster-name: {{ (lookup "config.openshift.io/v1" "Infrastructure" "" "cluster").status.infrastructureName }}
          - name: multiline
            type: detectMultilineException
          - name: journal-filter
            type: drop
            drop:
            - test:
              - field: .systemd.t.TRANSPORT
                notMatches: kernel
              - field: .systemd.t.SYSTEMD_UNIT
                notMatches: kubelet.service
            - test:
              - field: .systemd.t.SYSTEMD_UNIT
                matches: kubelet.service
              - field: .message
                matches: ^I[0-9]
              - field: .message
                notMatches: OOM event
          - name: important
            type: drop
            drop:
            - test:
              - field: .message
                notMatches: "(?i)critical|error"
              - field: .level
                matches: "trace|debug|default"
          - name: core-infra-log
            type: drop
            drop:
            - test:
              - field: .kubernetes.namespace_name
                notMatches: openshift-kube-apiserver|openshift-kube-controller-manager|openshift-controller-manager|openshift-kube-scheduler|openshift-authentication|openshift-ovn-kubernetes
          - name: audit-log-drop-verb
            type: drop
            drop:
            - test:
              - field: .verb
                matches: get|list|watch
          - name: audit-log-drop-resource
            type: drop
            drop:
            - test:
              - field: .objectRef.resource
                matches: lease|subjectaccessreview|tokenreview
          - name: audit-log-drop-username
            type: drop
            drop:
            - test:
              - field: .user.username
                matches: (olm-operator|openshift|hive|hypershift|multicluster|open-cluster|kiali|istio)
              - field: .user.username
                notMatches: (gitops)
          - name: event-prune
            type: prune
            prune:
              notIn:
              - .hostname
              - .kubernetes.container_name
              - .kubernetes.event
              - .kubernetes.namespace_name
              - .kubernetes.pod_name
              - .log_source
              - .log_type
              - .message
              - .openshift.labels
          - name: event-kafka-prune
            type: prune
            prune:
              notIn:
              - .kubernetes.event.involvedObject.name
              - .kubernetes.event.involvedObject.namespace
              - .kubernetes.event.lastTimestamp
              - .kubernetes.event.reason
              - .kubernetes.event.type
              - .kubernetes.event.eventTime
              - .log_source
              - .log_type
              - .message
              - .openshift.labels
          - name: event-kafka-drop
            type: drop
            drop:
            - test:
              - field: .kubernetes.event.type
                matches: Normal
          - name: journal-prune
            type: prune
            prune:
              notIn:
              - .hostname
              - .log_source
              - .log_type
              - .message
              - .systemd.u.SYSLOG_IDENTIFIER
              - .time
              - .openshift.labels
    {{hub- end hub}}
    {{hub- end hub}}
    {{- end }}
---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-extra
spec:
  evaluationInterval:
    compliant: 1m
    noncompliant: 1m
  remediationAction: enforce
  severity: high
  object-templates-raw: |
    {{- if not (hasKey (lookup "operators.coreos.com/v1alpha1" "Subscription" "openshift-gitops-operator" "openshift-gitops-operator").metadata.labels "policies.ignore") }}
    {{hub- if ne "none" (index .ManagedClusterLabels "policies.extra") hub}}
    - complianceType: musthave
      objectDefinition:
        apiVersion: pipelines.openshift.io/v1alpha1
        kind: GitopsService
        metadata:
          name: cluster
        spec:
          runOnInfra: true
          tolerations:
          - effect: NoSchedule
            key: node-role.kubernetes.io/infra
            operator: Exists
          - effect: NoExecute
            key: node.kubernetes.io/not-ready
            operator: Exists
            tolerationSeconds: 60
          - effect: NoExecute
            key: node.kubernetes.io/unreachable
            operator: Exists
            tolerationSeconds: 60
    - complianceType: musthave
      objectDefinition:
        apiVersion: argoproj.io/v1beta1
        kind: ArgoCD
        metadata:
          name: openshift-gitops
          namespace: openshift-gitops
        spec:
          applicationSet:
            resources:
              limits:
                cpu: "2"
                memory: 1Gi
              requests:
                cpu: 250m
                memory: 512Mi
            webhookServer:
              ingress:
                enabled: false
              route:
                enabled: false
          controller:
            processors: {}
            resources:
              limits:
                cpu: "4"
                memory: 4Gi
              requests:
                cpu: 250m
                memory: 1Gi
          extraConfig:
            accounts.admin: apiKey
          grafana:
            enabled: false
            ingress:
              enabled: false
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 250m
                memory: 128Mi
            route:
              enabled: false
          ha:
            enabled: {{hub if eq "dev" (index .ManagedClusterLabels "policies.extra") hub}}false{{hub else hub}}true{{hub end hub}}
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 250m
                memory: 128Mi
          initialSSHKnownHosts: {}
          monitoring:
            enabled: false
          notifications:
            enabled: true
          prometheus:
            enabled: false
            ingress:
              enabled: false
            route:
              enabled: false
          rbac:
            defaultPolicy: ""
            policy: |
              g, system:cluster-admins, role:admin
              g, cluster-admin, role:admin
            scopes: '[groups]'
          redis:
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 250m
                memory: 128Mi
          repo:
            replicas: 2
            resources:
              limits:
                cpu: "1"
                memory: 1Gi
              requests:
                cpu: 250m
                memory: 256Mi
          resourceExclusions: |
            - apiGroups:
              - tekton.dev
              clusters:
              - '*'
              kinds:
              - TaskRun
              - PipelineRun
          server:
            autoscale:
              enabled: false
            grpc:
              ingress:
                enabled: false
            ingress:
              enabled: false
            replicas: 2
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 125m
                memory: 128Mi
            route:
              enabled: true
            service:
              type: ""
    {{hub- end hub}}
    {{- end }}
---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-monitoring
spec:
  evaluationInterval:
    compliant: 1m
    noncompliant: 1m
  remediationAction: enforce
  severity: high
  object-templates-raw: |
    {{- if not (hasKey (lookup "v1" "ConfigMap" "openshift-monitoring" "cluster-monitoring-config").metadata.labels "policies.ignore") }}
    - complianceType: musthave
      objectDefinition:
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: cluster-monitoring-config
          namespace: openshift-monitoring
        data:
          config.yaml: |
            alertmanagerMain:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
    {{- if eq "Bound" (lookup "v1" "PersistentVolumeClaim" "openshift-monitoring" "alertmanager-main-db-alertmanager-main-0").status.phase }}
              volumeClaimTemplate:
                metadata:
                  name: alertmanager-main-db
                spec:
                  resources:
                    requests:
                      storage: 10Gi
    {{- end }}
            enableUserWorkload: false
            kubeStateMetrics:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
            metricsServer:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
            monitoringPlugin:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
            openshiftStateMetrics:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
            prometheusK8s:
              externalLabels:
                managed_cluster: {{ (lookup "config.openshift.io/v1" "Infrastructure" "" "cluster").status.infrastructureName }}
              nodeSelector:
                node-role.kubernetes.io/infra: ""
    {{- $np := "{{hub index .ManagedClusterLabels "policies.ns-prefix" hub}}" }}
    {{- $mn := "clushkube-monitoring" }}
    {{- if ne "" $np }}{{ $mn = (cat $np "-monitoring-ns" | replace " " "") }}{{ end }}
              remoteWrite:
              - url: http://kube-prometheus-stack-prometheus.{{ $mn }}.svc.cluster.local:9090/api/v1/write
                queueConfig:
                  minShards: 2
              retentionSize: 60GiB
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
    {{- if eq "Bound" (lookup "v1" "PersistentVolumeClaim" "openshift-monitoring" "prometheus-k8s-db-prometheus-k8s-0").status.phase }}
              volumeClaimTemplate:
                metadata:
                  name: prometheus-k8s-db
                spec:
                  resources:
                    requests:
                      storage: 90Gi
    {{- end }}
            prometheusOperator:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
            telemeterClient:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations: null
            thanosQuerier:
              nodeSelector:
                node-role.kubernetes.io/infra: ""
              tolerations:
              - effect: NoSchedule
                key: node-role.kubernetes.io/infra
                operator: Exists
    {{- end }}
---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-ingresscontroller
spec:
  evaluationInterval:
    compliant: 1m
    noncompliant: 1m
  remediationAction: enforce
  severity: high
  object-templates-raw: |
    {{- if not (hasKey (lookup "operator.openshift.io/v1" "IngressController" "openshift-ingress-operator" "default").metadata.labels "policies.ignore") }}
    {{- $rc := ( (lookup "machineconfiguration.openshift.io/v1" "MachineConfigPool" "" "infra").status.machineCount | toInt ) }}
    {{- if lt 1 $rc }}
    - complianceType: musthave
      objectDefinition:
        apiVersion: operator.openshift.io/v1
        kind: IngressController
        metadata:
          name: default
          namespace: openshift-ingress-operator
        spec:
          replicas: {{ $rc }}
    {{- end }}
    {{- end }}
---
