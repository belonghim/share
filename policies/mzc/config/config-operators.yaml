---
apiVersion: self-node-remediation.medik8s.io/v1alpha1
kind: SelfNodeRemediationConfig
metadata:
  name: self-node-remediation-config
  namespace: openshift-workload-availability
spec:
  customDsTolerations:
  - effect: NoSchedule
    operator: Exists
    key: node-role.kubernetes.io/infra
  peerApiServerTimeout: 30s
  peerDialTimeout: 30s
  peerRequestTimeout: 30s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-master
spec:
  minHealthy: 90%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/master
      operator: Exists
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-worker
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/worker
      operator: Exists
    - key: node-role.kubernetes.io/master
      operator: DoesNotExist
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-infra
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/infra
      operator: Exists
    - key: node-role.kubernetes.io/worker
      operator: DoesNotExist
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
apiVersion: remediation.medik8s.io/v1alpha1
kind: NodeHealthCheck
metadata:
  name: nodehealthcheck-acm
spec:
  minHealthy: 51%
  remediationTemplate:
    apiVersion: self-node-remediation.medik8s.io/v1alpha1
    name: self-node-remediation-automatic-strategy-template
    namespace: openshift-workload-availability
    kind: SelfNodeRemediationTemplate
  selector:
    matchExpressions:
    - key: node-role.kubernetes.io/acm
      operator: Exists
    - key: node-role.kubernetes.io/worker
      operator: DoesNotExist
    - key: node-role.kubernetes.io/infra
      operator: DoesNotExist
  unhealthyConditions:
  - type: Ready
    status: "False"
    duration: 300s
  - type: Ready
    status: Unknown
    duration: 300s
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: eventrouter
  namespace: openshift-logging
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: event-reader
rules:
- apiGroups: [""]
  resources: ["events"]
  verbs: ["get", "watch", "list"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: event-reader-binding
subjects:
- kind: ServiceAccount
  name: eventrouter
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: event-reader
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: eventrouter
  namespace: openshift-logging
data:
  config.json: |-
    {
      "sink": "stdout"
    }
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: eventrouter
  namespace: openshift-logging
  labels:
    component: "eventrouter"
    logging-infra: "eventrouter"
    provider: "openshift"
spec:
  selector:
    matchLabels:
      component: "eventrouter"
      logging-infra: "eventrouter"
      provider: "openshift"
  replicas: 1
  template:
    metadata:
      labels:
        component: "eventrouter"
        logging-infra: "eventrouter"
        provider: "openshift"
      name: eventrouter
    spec:
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      serviceAccount: eventrouter
      containers:
      - name: kube-eventrouter
        image: registry.redhat.io/openshift-logging/eventrouter-rhel9:v0.4
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
        volumeMounts:
        - name: config-volume
          mountPath: /etc/eventrouter
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      volumes:
      - name: config-volume
        configMap:
          name: eventrouter
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: log-collector
  namespace: openshift-logging
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: collect-application-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: collect-application-logs
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: collect-audit-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: collect-audit-logs
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: collect-infrastructure-logs
subjects:
- kind: ServiceAccount
  name: log-collector
  namespace: openshift-logging
roleRef:
  kind: ClusterRole
  name: collect-infrastructure-logs
---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-logforwarder
spec:
  remediationAction: enforce
  severity: high
  object-templates-raw: |
    {{hub if ne "" (index .PolicyMetadata.annotations "policies.log-brokers") hub}}
    {{hub if ne "" (index .PolicyMetadata.annotations "policies.log-topic") hub}}
    - complianceType: musthave
      objectDefinition:
        apiVersion: observability.openshift.io/v1
        kind: ClusterLogForwarder
        metadata:
          name: log-forwarder
          namespace: openshift-logging
        spec:
          managementState: Managed
          collector:
            resources:
              limits:
                cpu: "1"
                memory: 2Gi
              requests:
                cpu: "1"
                memory: 2Gi
          serviceAccount:
            name: log-collector
          outputs:
          - name: kafka-receiver
            type: kafka
            kafka:
              brokers: {{hub index .PolicyMetadata.annotations "policies.log-brokers" hub}}
              topic: {{hub index .PolicyMetadata.annotations "policies.log-topic" hub}}
              tuning:
                deliveryMode: AtLeastOnce
                maxWrite: 10M
                compression: none
          pipelines:
          - name: audit-log
            inputRefs:
            - audit
            outputRefs:
            - kafka-receiver
            filterRefs:
            - add-cluster-name
          - name: infra-log
            inputRefs:
            - infrastructure
            outputRefs:
            - kafka-receiver
            filterRefs:
            - add-cluster-name
          filters:
          - name: add-cluster-name
            type: openshiftLabels
            openshiftLabels:
              cluster-name: {{ fromClusterClaim "name" }}
    {{hub end hub}}
    {{hub end hub}}
---
apiVersion: policy.open-cluster-management.io/v1
kind: ConfigurationPolicy
metadata:
  name: config-operators-extra
spec:
  remediationAction: enforce
  severity: high
  object-templates-raw: |
    {{hub if ne "none" (index .ManagedClusterLabels "policies.extra") hub}}
    - complianceType: musthave
      objectDefinition:
        apiVersion: argoproj.io/v1beta1
        kind: ArgoCD
        metadata:
          name: openshift-gitops
          namespace: openshift-gitops
        spec:
          applicationSet:
            resources:
              limits:
                cpu: "2"
                memory: 1Gi
              requests:
                cpu: 250m
                memory: 512Mi
            webhookServer:
              ingress:
                enabled: false
              route:
                enabled: false
          controller:
            processors: {}
            resources:
              limits:
                cpu: "2"
                memory: 2Gi
              requests:
                cpu: 250m
                memory: 1Gi
          extraConfig:
            accounts.admin: apiKey
          grafana:
            enabled: false
            ingress:
              enabled: false
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 250m
                memory: 128Mi
            route:
              enabled: false
          ha:
            enabled: true
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 250m
                memory: 128Mi
          initialSSHKnownHosts: {}
          monitoring:
            enabled: false
          nodePlacement:
            nodeSelector:
              node-role.kubernetes.io/infra: ""
          notifications:
            enabled: true
          prometheus:
            enabled: false
            ingress:
              enabled: false
            route:
              enabled: false
          rbac:
            defaultPolicy: ""
            policy: |
              g, system:cluster-admins, role:admin
              g, cluster-admins, role:admin
            scopes: '[groups]'
          redis:
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 250m
                memory: 128Mi
          repo:
            replicas: 2
            resources:
              limits:
                cpu: "1"
                memory: 1Gi
              requests:
                cpu: 250m
                memory: 256Mi
          resourceExclusions: |
            - apiGroups:
              - tekton.dev
              clusters:
              - '*'
              kinds:
              - TaskRun
              - PipelineRun
          server:
            autoscale:
              enabled: false
            grpc:
              ingress:
                enabled: false
            ingress:
              enabled: false
            replicas: 2
            resources:
              limits:
                cpu: 500m
                memory: 256Mi
              requests:
                cpu: 125m
                memory: 128Mi
            route:
              enabled: true
            service:
              type: ""
    {{hub end hub}}
---
